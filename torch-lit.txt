Searching 73 files for "*****"

/home/fulcrum/Projects/tensor_selene/selene_sdk/evaluate_model.py:
    7  
    8  import numpy as np
    9: import torch
   10: import torch.nn as nn
   11: from torch.autograd import Variable
   12  
   13  from .sequences import Genome
   ..
   99          self.criterion = criterion
  100  
  101:         trained_model = torch.load(
  102              trained_model_path, map_location=lambda storage, location: storage)
  103          if "state_dict" in trained_model:
  ...
  211          all_predictions = []
  212          for (inputs, targets) in self._test_data:
  213:             inputs = torch.Tensor(inputs)
  214:             targets = torch.Tensor(targets[:, self._use_ixs])
  215  
  216              if self.use_cuda:
  217                  inputs = inputs.cuda()
  218                  targets = targets.cuda()
  219:             with torch.no_grad():
  220                  inputs = Variable(inputs)
  221                  targets = Variable(targets)

/home/fulcrum/Projects/tensor_selene/selene_sdk/predict/_common.py:
    5  
    6  import numpy as np
    7: import torch
    8: from torch.autograd import Variable
    9  
   10  from ..utils import _is_lua_trained_model
   ..
   87  
   88      """
   89:     inputs = torch.Tensor(batch_sequences)
   90      if use_cuda:
   91          inputs = inputs.cuda()
   92:     with torch.no_grad():
   93          inputs = Variable(inputs)
   94  

/home/fulcrum/Projects/tensor_selene/selene_sdk/predict/model_predict.py:
   10  import numpy as np
   11  import pyfaidx
   12: import torch
   13: import torch.nn as nn
   14  
   15  from ._common import _pad_sequence
  ...
  133  
  134          if isinstance(trained_model_path, str):
  135:             trained_model = torch.load(
  136                  trained_model_path,
  137                  map_location=lambda storage, location: storage)
  ...
  142              state_dicts = []
  143              for mp in trained_model_path:
  144:                 state_dict = torch.load(
  145                      mp, map_location=lambda storage, location: storage)
  146                  state_dicts.append(state_dict)

/home/fulcrum/Projects/tensor_selene/selene_sdk/samplers/dataloader.py:
    6  import  sys
    .
    8  import h5py
    9  import numpy as np
   10: import torch
   11  
   12  from functools import wraps
   13: from torch.utils.data import Dataset, DataLoader
   14  
   15
  ...
  213              else:
  214                  targets = targets[:self.t_len]
  215:         return (torch.from_numpy(sequence.astype(np.float32)),
  216:                 torch.from_numpy(targets.astype(np.float32)))
  217  
  218      @init
  ...
  304          }
  305          if use_subset is not None:
  306:             from torch.utils.data.sampler import SubsetRandomSampler
  307              if isinstance(use_subset, int):
  308                  use_subset = list(range(use_subset))

/home/fulcrum/Projects/tensor_selene/selene_sdk/samplers/multi_sampler.py:
    6  """
    7  import numpy as np
    8: from torch.utils.data import DataLoader
    9  
   10  from .sampler import Sampler

/home/fulcrum/Projects/tensor_selene/selene_sdk/train_model.py:
   10  
   11  import numpy as np
   12: import torch
   13: import torch.nn as nn
   14: from torch.autograd import Variable
   15: from torch.optim.lr_scheduler import ReduceLROnPlateau
   16  from sklearn.metrics import roc_auc_score
   17  from sklearn.metrics import average_precision_score
  ...
  221                          self.max_steps))
  222  
  223:         torch.set_num_threads(cpu_n_threads)
  224  
  225          self.use_cuda = use_cuda
  ...
  256  
  257      def _load_checkpoint(self, checkpoint_resume):
  258:         checkpoint = torch.load(
  259              checkpoint_resume,
  260              map_location=lambda storage, location: storage)
  ...
  262              raise ValueError(
  263                  ("'state_dict' not found in file {0} "
  264:                  "loaded with method `torch.load`. Selene does not support "
  265                   "continued training of models that were not originally "
  266                   "trained using Selene.").format(checkpoint_resume))
  ...
  279              for state in self.optimizer.state.values():
  280                  for k, v in state.items():
  281:                     if isinstance(v, torch.Tensor):
  282                          state[k] = v.cuda()
  283  
  ...
  441  
  442          inputs, targets = self._get_batch()
  443:         inputs = torch.Tensor(inputs)
  444:         targets = torch.Tensor(targets)
  445  
  446          if self.use_cuda:
  ...
  493  
  494          for (inputs, targets) in data_in_batches:
  495:             inputs = torch.Tensor(inputs)
  496:             targets = torch.Tensor(targets)
  497  
  498              if self.use_cuda:
  ...
  500                  targets = targets.cuda()
  501  
  502:             with torch.no_grad():
  503                  inputs = Variable(inputs)
  504                  targets = Variable(targets)
  ...
  642          cp_filepath = os.path.join(
  643              self.output_dir, filename)
  644:         torch.save(state, "{0}.pth.tar".format(cp_filepath))
  645          if is_best:
  646              best_filepath = os.path.join(self.output_dir, "best_model")

/home/fulcrum/Projects/tensor_selene/selene_sdk/utils/config_utils.py:
   10  import types
   11  
   12: import torch
   13  
   14  from . import _is_lua_trained_model
   ..
  333      if "random_seed" in configs:
  334          seed = configs["random_seed"]
  335:         torch.manual_seed(seed)
  336:         torch.cuda.manual_seed_all(seed)
  337      else:
  338          print("Warning: no random seed specified in config file. "

/home/fulcrum/Projects/tensor_selene/selene_sdk/utils/example_model.py:
   13  """
   14  import numpy as np
   15: import torch
   16: import torch.nn as nn
   ..
  117:     return (torch.optim.SGD,
  118              {"lr": lr, "weight_decay": 1e-6, "momentum": 0.9})
  119  

/home/fulcrum/Projects/tensor_selene/selene_sdk/utils/multi_model_wrapper.py:
    5  Loads multiple models and concatenates their outputs.
    6  """
    7: import torch
    8: import torch.nn as nn
    9  
   10  
   ..
   46  
   47      def forward(self, x):
   48:         return torch.cat(
   49              [sm(x) for sm in self.sub_models], self._concat_dim)
   50  

/home/fulcrum/Projects/tensor_selene/selene_sdk/utils/non_strand_specific_module.py:
    2  This module provides the NonStrandSpecific class.
    3  """
    4: import torch
    5: from torch.nn.modules import Module
    6  
    7  from . import _is_lua_trained_model
   ..
   20      x = x.view(
   21          x.size(0), x.size(1), -1)[:, getattr(
   22:             torch.arange(x.size(1)-1, -1, -1),
   23              ('cpu','cuda')[x.is_cuda])().long(), :]
   24      return x.view(xsize)
   ..
   64          if self.from_lua:
   65              reverse_input = _flip(
   66:                 _flip(torch.squeeze(input, 2), 1), 2).unsqueeze_(2)
   67          else:
   68              reverse_input = _flip(_flip(input, 1), 2)
   ..
   74              return (output + output_from_rev) / 2
   75          else:
   76:             return torch.max(output, output_from_rev)
   77  
   78  

49 matches across 10 files
